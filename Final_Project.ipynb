{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import All Necessary Modules And Setup Project\n",
    "\n",
    "If you get any errors when importing these, ensure you run the commands:\n",
    "```bash\n",
    "$ python -m pip install -r requirements.txt\n",
    "```\n",
    "to install all necessary modules for this project. This command must be run from inside of this project directory.\n",
    "\n",
    "It is recommended to use virtual environments for this project to ensure there is no conflicting package versions on your system.\n",
    "\n",
    "Activate the virtual environment (if needed), run the pip install command, and then launch Jupyter Lab inside this project to get this project running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line to execute the pip install\n",
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from measure_incremental_development.compute import calculate_mid, classify_snapshots\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Auxiliary Modules and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from projectConstants import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`projectConstants` defines various constants (namely, column names) that are used throughout the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getSubmissionDataframes import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`getSubmissionDataframes` contains the following functions:\n",
    "\n",
    "*   `getFileInStudentSubmission`\n",
    "*   `getStudentSubmission`\n",
    "*   `filterDownToRunAndEdits`\n",
    "*   `filterDownToRunAndEditsAndPastes`\n",
    "*   `getStudentSubmissionRunsAndEdits`\n",
    "*   `getFileInStudentSubmissionRunsAndEdits`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reconstructSubmissions import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`reconstructSubmissions` has the functions:\n",
    "\n",
    "*   `reconstructSingleFileDebugger`\n",
    "*   `reconstructFinalFile`\n",
    "*   `reconstructFileAtRunEvents`\n",
    "*   `reconstructProjectAtRunEvents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from viewReconstructions import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`viewReconstructions` has the following functions:\n",
    "\n",
    "*   `viewFinalReconstructedProject`\n",
    "*   `viewReconstructedProjectStates`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getStudentProjectInfo import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`getStudentProjectInfo` has the following function:\n",
    "\n",
    "*   `getStudentProjectList`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filterOutBadReconstructions import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`filterOutBadReconstructions` has the following functions:\n",
    "\n",
    "*   `getFileReconstructionDF`\n",
    "    *   Get the raw file reconstructions dataframe\n",
    "*   `getProjectReconstructionDF`\n",
    "    *   Same as above, but if any file in a project fails at reconstructing, the whole project is marked as a failed reconstruction\n",
    "*   `getOnlyBadFileReconstructionsDF`\n",
    "    *   Get a DF like `getFileReconstructionDF` returns, containing *ONLY* the bad file reconstructions\n",
    "*   `getOnlyBadProjectReconstructions`\n",
    "    *   Get a DF like `getProjectReconstructionDF` returns, containing *ONLY* the bad project reconstructions\n",
    "*   `mergeKeystrokesWithFileReconstructions`\n",
    "    *   Merge a keystroke dataframe with the *file* reconstruction df on `SubjectID, AssignmentID, CodeStateSection`\n",
    "*   `mergeKeystrokesWithProjectReconstructions`\n",
    "    *   Merge a keystroke dataframe with the *project* reconstruction df on `SubjectID, AssignmentID`\n",
    "*   `getKeystrokesDFWithoutBadFileReconstructions`\n",
    "    *   Filter down the keystroke dataframe to remove information related to *files* that reconstruct incorrectly\n",
    "*   `getKeystrokesDFWithoutBadProjectReconstructions`\n",
    "    *   Filter down the keystroke dataframe to remove information related to *projects* that reconstruct incorrectly\n",
    "\n",
    "Unless granularity of the keystroke data is desired, the `getKeystrokesDFWithoutBadProjectReconstructions` will probably be the only needed function.\n",
    "\n",
    "NOTE: The reconstruction data used for these functions was generated by the `checkSubmissions.sh` script and `determineReconstructionFailures.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from midScoreFunctions import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`midScoreFunctions` has the following functions:\n",
    "\n",
    "*   `remove_empty_at_start`\n",
    "*   `get_scores`\n",
    "*   `get_mid_score_row`\n",
    "*   `get_mid_score_all`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeBetweenRuns import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`timeBetweenRuns` has the following functions:\n",
    "\n",
    "*   `getTimestampRow`\n",
    "*   `getFilteredRunEvents`\n",
    "*   `getTimeBetweenRuns`\n",
    "*   `getTimeBetweenRunsDf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codingSessionFunctions import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`codingSessionFunctions` has the following functions:\n",
    "\n",
    "*   `markEventsByCodingSessions`\n",
    "*   `getIndividualSessionInfo`\n",
    "*   `getCodingSessionsDf`\n",
    "*   `sessionInfoToAssignmentInfo`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keystroke_df_unedited = pd.read_csv(\"data/keystrokes.csv\")\n",
    "student_df_unedited = pd.read_csv(\"data/students.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Datasets For Modification\n",
    "\n",
    "This preserves the initial datasets, in case we ever need to bring an unedited column/row back into anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keystroke_df = keystroke_df_unedited.copy()\n",
    "student_df = student_df_unedited.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter Keystroke Data To Only Projects That Have Reconstructed Correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keystroke_df = getKeystrokesDFWithoutBadProjectReconstructions(keystroke_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Information And Keystroke Dataframes For Each `Student,Project` pair\n",
    "\n",
    "**NOTE:** This may take a few minutes to compute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_df, run_events_df, final_data = getStudentProjectList(student_df, keystroke_df)\n",
    "\n",
    "print(len(projects_df), len(run_events_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all students with a submission for the assignment\n",
    "\n",
    "for student, assign, df in final_data:\n",
    "    if len(df) > 0:\n",
    "        print(student, assign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for student, assign, df in final_data:\n",
    "    if len(df) > 0:\n",
    "        # print(len(df))\n",
    "        print(50*'=')\n",
    "        print(student, assign)\n",
    "        viewFinalReconstructedProject(df)\n",
    "        print(50*'=')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add MID Library\n",
    "\n",
    "- 0-2 Likely Incremental\n",
    "- 2-2.5 Somewhat Incremental\n",
    "- 2.5-3 Somewhat Non-Incremental\n",
    "- 3+ Likely Non-Incremental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate MID statistc for student and assignmemt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_scores('Student10', 'Assign10', student_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_df = get_mid_score_all(final_data, student_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_df.to_csv('./data/mid_scores.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to get the time between runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runEvents = getFilteredRunEvents(keystroke_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeBetweenRunsDf = getTimeBetweenRunsDf(keystroke_df, final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(timeBetweenRunsDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeBetweenRunsDf.to_csv('./data/timeBetweenRuns.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Coding Sessions\n",
    "\n",
    "#### Defined as keypresses within 5 minutes of eachother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from projectConstants import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from timeBetweenRuns import *\n",
    "\n",
    "\n",
    "def markEventsByCodingSessions(df, student, assignment):\n",
    "    '''\n",
    "    For a specific (student, assignment) pair, make a new dataframe that marks all these events with a coding session\n",
    "\n",
    "    Coding sessions end if there's more than 5 minutes from last event\n",
    "    '''\n",
    "    assnSessionDf = df[\n",
    "        (df.SubjectID == student) & (df.AssignmentID == assignment)\n",
    "        & (\n",
    "        # We do not want any X-Attention or X-Keystroke events, or Editor Close Actions\n",
    "          ~ (\n",
    "              ( df.EventType == 'X-Attention' )\n",
    "            | ( df.EventType == 'X-Keystroke' ) # X-Keystrokes are essentially duplicates of edits with some fickle-behaviors\n",
    "            | ( ( df.EventType == 'X-Action' ) & (df['X-Metadata'] == 'Close Active Editor') )\n",
    "          )\n",
    "        )\n",
    "        ].copy()\n",
    "\n",
    "    assnSessionDf[DATE_TIME_KEY] = pd.to_datetime(assnSessionDf.ClientTimestamp, unit='ms') \n",
    "    assnSessionDf[SESSION_ID_KEY] = -1\n",
    "    assnSessionDf[EVENT_TIME_DIFF_KEY] = np.NaN\n",
    "    assnSessionDf[INSESSION_RUNTIME_DIFF_KEY] = np.NaN\n",
    "    assnSessionDf[INSESSION_HAS_RAN_CODE_KEY] = 0\n",
    "\n",
    "    # sort by timestamp\n",
    "    assnSessionDf.sort_values(by=DATE_TIME_KEY, inplace=True)\n",
    "\n",
    "    if assnSessionDf.size > 0:\n",
    "        lastEventTime = assnSessionDf.head(1)[DATE_TIME_KEY].values[0]\n",
    "        lastRunTime = lastEventTime\n",
    "\n",
    "    # 5 minutes from last event, not start of the session\n",
    "    sessionId = 0\n",
    "    hasRanCodeInSession = 0\n",
    "\n",
    "    for i, row in assnSessionDf.iterrows():\n",
    "        diff = row[DATE_TIME_KEY] - lastEventTime\n",
    "        minutes_diff = diff.total_seconds() / 60\n",
    "\n",
    "        if minutes_diff > 5:\n",
    "            sessionId += 1\n",
    "            lastRunTime = row[DATE_TIME_KEY]\n",
    "            hasRanCodeInSession = 0\n",
    "            # assnSessionDf.at[i, EVENT_TIME_DIFF_KEY] = np.NaN\n",
    "        else:\n",
    "            # If this event is still part of the same coding session, we note the diff time\n",
    "            # If it's not, leave it as NaN\n",
    "            assnSessionDf.at[i, EVENT_TIME_DIFF_KEY] = diff.total_seconds()\n",
    "\n",
    "        assnSessionDf.at[i, INSESSION_RUNTIME_DIFF_KEY] = (row[DATE_TIME_KEY] - lastRunTime).total_seconds()\n",
    "        assnSessionDf.at[i, INSESSION_HAS_RAN_CODE_KEY] = hasRanCodeInSession\n",
    "        if row.EventType == 'Run.Program' and row['X-Metadata'] == 'Start':\n",
    "            hasRanCodeInSession = 1\n",
    "            # Compute time since last run in this session\n",
    "            lastRunTime = row[DATE_TIME_KEY]\n",
    "\n",
    "        assnSessionDf.at[i,SESSION_ID_KEY] = sessionId\n",
    "\n",
    "\n",
    "        lastEventTime = row[DATE_TIME_KEY]\n",
    "\n",
    "    return assnSessionDf\n",
    "\n",
    "\n",
    "def getIndividualSessionInfo(df):\n",
    "    '''\n",
    "    Get information for each coding sesssion for a given (Student,Assignment)\n",
    "\n",
    "    df should contain keystroke/event data for a given student/assignment with session numbers and time-diffs between sessions marked\n",
    "        (See markEventsByCodingSessions)\n",
    "    \n",
    "    '''\n",
    "    if df.size == 0:\n",
    "        return None\n",
    "\n",
    "    # The given dataframe should only be for one (Student,Assignment)\n",
    "\n",
    "    allSessionIds = df[SESSION_ID_KEY].unique()\n",
    "    student = df.head(1)[SUBJECT_ID_KEY].values[0]\n",
    "    assn = df.head(1)[ASSIGNMENT_ID_KEY].values[0]\n",
    "\n",
    "    studentSessionID = [student] * len(allSessionIds)\n",
    "    assnSessionID = [assn] * len(allSessionIds)\n",
    "\n",
    "    sessionIdsColumn = []\n",
    "    sessionStartTimes = []\n",
    "    sessionEndTimes = []\n",
    "    sessionLengths = []\n",
    "    sessionNumEvents = []\n",
    "    sessionAvgEventDiffTime = []\n",
    "    sessionNumEventsBeforeRun = []\n",
    "    sessionNumEventsAfterRun = []\n",
    "    sessionNumRuns = []\n",
    "    sessionAvgTimeBetweenRuns = []\n",
    "\n",
    "    for sessionId in allSessionIds:\n",
    "        # Reduce df down to just this session\n",
    "        sessionDf = df[(df[SESSION_ID_KEY] == sessionId)].copy()\n",
    "        # sort by dates just in case\n",
    "        sessionDf.sort_values(by=DATE_TIME_KEY, inplace=True)\n",
    "\n",
    "        startTime = sessionDf.head(1)[CLIENT_TIMESTAMP_KEY].values[0]\n",
    "        endTime = sessionDf.tail(1)[CLIENT_TIMESTAMP_KEY].values[0]\n",
    "        # subtract start session time and end session time to get total session time\n",
    "        lengthTime = endTime - startTime\n",
    "\n",
    "\n",
    "        # Get Only Run Events\n",
    "        runEvents = sessionDf[(sessionDf.EventType == 'Run.Program') & (sessionDf['X-Metadata'] == 'Start')]\n",
    "        avgTimeBetweenRuns = runEvents[INSESSION_RUNTIME_DIFF_KEY].mean()\n",
    "\n",
    "        avgEventDiffTime = sessionDf[EVENT_TIME_DIFF_KEY].mean()\n",
    "\n",
    "        eventsBeforeRun = sessionDf[sessionDf[INSESSION_HAS_RAN_CODE_KEY] == 0]\n",
    "        eventsAfterRun = sessionDf[sessionDf[INSESSION_HAS_RAN_CODE_KEY] == 1]\n",
    "\n",
    "\n",
    "\n",
    "        # Add all data for this session to a list\n",
    "        sessionIdsColumn.append(sessionId)\n",
    "        sessionStartTimes.append(startTime)\n",
    "        sessionEndTimes.append(endTime)\n",
    "        sessionLengths.append(lengthTime)\n",
    "        sessionNumEvents.append(len(sessionDf))\n",
    "        sessionNumEventsBeforeRun.append(len(eventsBeforeRun))\n",
    "        sessionNumEventsAfterRun.append(len(eventsAfterRun))\n",
    "        sessionAvgEventDiffTime.append(avgEventDiffTime)\n",
    "        sessionNumRuns.append(len(runEvents))\n",
    "        sessionAvgTimeBetweenRuns.append(avgTimeBetweenRuns)\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            SUBJECT_ID_KEY: studentSessionID,\n",
    "            ASSIGNMENT_ID_KEY: assnSessionID,\n",
    "            SESSION_ID_KEY: sessionIdsColumn,\n",
    "            SESSION_START_TIME_KEY: sessionStartTimes,\n",
    "            SESSION_END_TIME_KEY: sessionEndTimes,\n",
    "            SESSION_TIME_KEY: sessionLengths,\n",
    "            NUMBER_EVENTS_KEY: sessionNumEvents,\n",
    "            NUMBER_EVENTS_BEFORE_RUN_KEY: sessionNumEventsBeforeRun,\n",
    "            NUMBER_EVENTS_AFTER_RUN_KEY: sessionNumEventsAfterRun,\n",
    "            AVG_EVENTDIFF_TIME_KEY: sessionAvgEventDiffTime,\n",
    "            NUMBER_RUNS_KEY: sessionNumRuns,\n",
    "            AVG_TIME_BETWEEN_RUNS_KEY: sessionAvgTimeBetweenRuns,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def condenseCodingSessions(session_info_df, allCodingSessionsDf):\n",
    "    '''\n",
    "    Convert a dataframe containing individual session info into a dataframe containing info for all sessions on an assignment\n",
    "    '''\n",
    "\n",
    "    allCodingSessionsDf[SUBJECT_ID_KEY].append(\n",
    "        session_info_df[SUBJECT_ID_KEY].head(1).values[0]\n",
    "    )\n",
    "    allCodingSessionsDf[ASSIGNMENT_ID_KEY].append(\n",
    "        session_info_df[ASSIGNMENT_ID_KEY].head(1).values[0]\n",
    "    )\n",
    "    allCodingSessionsDf[SESSION_COUNT_KEY].append(\n",
    "        session_info_df[SESSION_ID_KEY].count()\n",
    "    )\n",
    "    allCodingSessionsDf[TOTAL_ASSIGNMENT_TIME_KEY].append(\n",
    "        session_info_df[SESSION_TIME_KEY].sum()\n",
    "    )\n",
    "    allCodingSessionsDf[NUMBER_EVENTS_KEY].append(\n",
    "        session_info_df[NUMBER_EVENTS_KEY].sum()\n",
    "    )\n",
    "    allCodingSessionsDf[NUMBER_EVENTS_BEFORE_RUN_IN_SESSION_KEY].append(\n",
    "        session_info_df[NUMBER_EVENTS_BEFORE_RUN_KEY].sum()\n",
    "    )\n",
    "    allCodingSessionsDf[NUMBER_EVENTS_AFTER_RUN_IN_SESSION_KEY].append(\n",
    "        session_info_df[NUMBER_EVENTS_AFTER_RUN_KEY].sum()\n",
    "    )\n",
    "    allCodingSessionsDf[NUMBER_RUNS_KEY].append(\n",
    "        session_info_df[NUMBER_RUNS_KEY].sum()\n",
    "    )\n",
    "    allCodingSessionsDf[FIRST_SESSION_START_KEY].append( \n",
    "        session_info_df.head(1)[SESSION_START_TIME_KEY].values[0]\n",
    "    )\n",
    "    allCodingSessionsDf[LAST_SESSION_END_KEY].append(\n",
    "        session_info_df.tail(1)[SESSION_END_TIME_KEY].values[0]\n",
    "    )\n",
    "    allCodingSessionsDf[AVG_EVENTDIFF_TIME_KEY].append(\n",
    "        session_info_df[AVG_EVENTDIFF_TIME_KEY].mean()\n",
    "    )\n",
    "    allCodingSessionsDf[AVG_TIME_BETWEEN_RUNS_KEY].append(\n",
    "        session_info_df[AVG_TIME_BETWEEN_RUNS_KEY].mean()\n",
    "    )\n",
    "\n",
    "\n",
    "def getCodingSessionsDf(keystroke_df, final_data):\n",
    "    '''\n",
    "    Get coding session for each student and assignment, where coding session is events within 5 minutes\n",
    "    \n",
    "    Returns a dataframe containing an entry for each unique coding session\n",
    "    '''\n",
    "\n",
    "    individualCodingSessionDf = pd.DataFrame()\n",
    "    allCodingSessionsDf = {\n",
    "        SUBJECT_ID_KEY: [],\n",
    "        ASSIGNMENT_ID_KEY: [],\n",
    "        SESSION_COUNT_KEY : [],\n",
    "        TOTAL_ASSIGNMENT_TIME_KEY: [],\n",
    "        NUMBER_EVENTS_KEY: [],\n",
    "        NUMBER_EVENTS_BEFORE_RUN_IN_SESSION_KEY: [],\n",
    "        NUMBER_EVENTS_AFTER_RUN_IN_SESSION_KEY: [],\n",
    "        NUMBER_RUNS_KEY: [],\n",
    "        FIRST_SESSION_START_KEY: [],\n",
    "        LAST_SESSION_END_KEY: [],\n",
    "        AVG_EVENTDIFF_TIME_KEY: [],\n",
    "        AVG_TIME_BETWEEN_RUNS_KEY: [],\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    for student, assignment, _ in final_data:\n",
    "\n",
    "        # Get a dataframe with keystroke info for this (student,assignment), marked by coding sessions\n",
    "        codingSessionAssignmentDf = markEventsByCodingSessions(keystroke_df, student, assignment)\n",
    "\n",
    "        # Compute info for each coding session\n",
    "        oneCodingSessionInfoDf = getIndividualSessionInfo(codingSessionAssignmentDf)\n",
    "\n",
    "        if oneCodingSessionInfoDf is None:\n",
    "            continue\n",
    "\n",
    "\n",
    "        individualCodingSessionDf = pd.concat([individualCodingSessionDf, oneCodingSessionInfoDf], ignore_index=True)\n",
    "        condenseCodingSessions(oneCodingSessionInfoDf, allCodingSessionsDf)\n",
    "\n",
    "    return individualCodingSessionDf, pd.DataFrame(allCodingSessionsDf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCodingSessions, condensedCodingSessions = getCodingSessionsDf(keystroke_df, final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(singleSession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCodingSessions.to_csv('./data/codingSessions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condensedCodingSessions.to_csv('./data/assignmentBehaviorInfo.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "5e7cd3a884995e5ac0fa852e707a391ad35b963e757ae698c795d1558dfb018c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
