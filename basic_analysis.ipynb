{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Visualization\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from projectConstants import * "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load All Data Into `*_unedited` Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_scores_unedited = pd.read_csv(\"data/mid_scores.csv\")\n",
    "mid_scores = mid_scores_unedited.copy()\n",
    "coding_sessions_unedited = pd.read_csv(\"data/codingSessions.csv\")\n",
    "coding_sessions = coding_sessions_unedited.copy()\n",
    "assignment_behavior_info_unedited = pd.read_csv(\"data/assignmentBehaviorInfo.csv\")\n",
    "assignment_behavior_info = assignment_behavior_info_unedited.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Merged Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_scores_with_behavior_info = mid_scores.merge(assignment_behavior_info, on=[SUBJECT_ID_KEY, ASSIGNMENT_ID_KEY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_scores_with_behavior_info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Mid Scores over Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_scores.sort_values('AssignmentID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=mid_scores, x='AssignmentID', y='MID_Score', hue='SubjectID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=mid_scores, x='MID_Score', y='AssignmentScore')\n",
    "plt.savefig('./images/AssignmentScore_MidScore.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_scores.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = filter(lambda v: v != 'Unnamed: 0', mid_scores.columns)\n",
    "pairs = list(itertools.combinations(variables, 2))\n",
    "\n",
    "fig, axs = plt.subplots(len(pairs) // 2, 2, figsize=(12,48))\n",
    "for col in range(len(pairs) // 2):\n",
    "    for row in range(2):\n",
    "        pair = pairs.pop(0)\n",
    "        ax = axs[col][row]\n",
    "        sns.scatterplot(data=mid_scores, x=pair[0], y=pair[1], hue='Incremental', ax=ax)\n",
    "        ax.set_title(f'{pair[0]} vs {pair[1]}')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=mid_scores, x='AssignmentID', y='MID_Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=mid_scores, x='AssignmentID')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mid Score in Relation to Final Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students = mid_scores[SUBJECT_ID_KEY].unique()\n",
    "\n",
    "score_df = pd.DataFrame()\n",
    "\n",
    "for student in students: \n",
    "    student_df = mid_scores.loc[mid_scores[SUBJECT_ID_KEY] == student]\n",
    "    # do those with 3 or more assignments\n",
    "    if len(student_df[ASSIGNMENT_ID_KEY]) > 3:\n",
    "        row = pd.DataFrame({\n",
    "                SUBJECT_ID_KEY: student,\n",
    "                FINAL_SCORE_KEY: student_df[FINAL_SCORE_KEY].unique()[0],\n",
    "                'IncrementalPercent': ((student_df[INCREMENTAL_KEY]==1).sum() / student_df[INCREMENTAL_KEY].count()) * 100\n",
    "        }, index=[0])\n",
    "        score_df = pd.concat([score_df, row], ignore_index=True)\n",
    "    # print(incremental_development_count)\n",
    "score_df = score_df.dropna()\n",
    "\n",
    "ax = sns.scatterplot(x=FINAL_SCORE_KEY, y='IncrementalPercent', data=score_df)\n",
    "ax.set(title='Incremental Development in Relation to Final Score')\n",
    "ax.set_ylabel(\"Percentage of Incremental Development Over Course\")\n",
    "ax.set_xlabel(\"Final Score\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Time Between Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_scores_with_behavior_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at assignments for each student, average time between runs per assignment\n",
    "\n",
    "# CURRENTLY BROKEN, IDK WHY\n",
    "\n",
    "# averagePerRunDf = pd.DataFrame()\n",
    "# students = mid_scores_with_behavior_info[SUBJECT_ID_KEY].unique()\n",
    "# assignments = mid_scores_with_behavior_info[ASSIGNMENT_ID_KEY].unique()\n",
    "# studentAssignment = pd.DataFrame()\n",
    "# for student in students:\n",
    "#     for assignment in assignments: \n",
    "#         studentAssignment = mid_scores_with_behavior_info[(mid_scores_with_behavior_info.SubjectID == student)&(mid_scores_with_behavior_info.AssignmentID == assignment)].copy()\n",
    "#         # mean = studentAssignment[DIFF_KEY].mean()\n",
    "#         studentAssignment = studentAssignment.dropna()\n",
    "\n",
    "#         # get number of runs per assignment\n",
    "#         numRuns = (studentAssignment[ASSIGNMENT_ID_KEY] == assignment)[NUMBER_RUNS_KEY].values[0]\n",
    "#         if len(studentAssignment) > 0:\n",
    "#             # averageTime = pd.to_timedelta(int((hoursAsSeconds + minutesAsSeconds + secondsValue) / len(studentAssignment)), unit='s')\n",
    "#             averageTime = float((studentAssignment[ASSIGNMENT_ID_KEY] == assignment)[AVG_TIME_BETWEEN_RUNS_KEY].values[0])\n",
    "#             averageRunRow = pd.DataFrame({SUBJECT_ID_KEY: student, \n",
    "#                                           ASSIGNMENT_ID_KEY: assignment, \n",
    "#                                           MID_SCORE_KEY: studentAssignment[MID_SCORE_KEY].unique()[0] if len(studentAssignment[MID_SCORE_KEY].unique()) > 0 else -1, \n",
    "#                                           'AverageTimePerRun': averageTime,\n",
    "#                                           'NumRunsPerAssignment': numRuns}, \n",
    "#                                           index=[0])\n",
    "#             averagePerRunDf = pd.concat([averagePerRunDf, averageRunRow], ignore_index=True)\n",
    "# display(averagePerRunDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BROKEN BECAUSE OF THE ABOVE\n",
    "\n",
    "# for assignment in assignments:\n",
    "#     # x is student\n",
    "#     # y is average time\n",
    "#     assignmentAvgPerRunDf = averagePerRunDf[(averagePerRunDf.AssignmentID == assignment)].copy()\n",
    "#     ax = sns.scatterplot(x=SUBJECT_ID_KEY, y='AverageTimePerRun', data=assignmentAvgPerRunDf)\n",
    "#     ax.set(title=f'Avg Time Between Runs Per Student {assignment}')\n",
    "#     ax.set_ylabel(\"Avg Time Between Runs\")\n",
    "#     ax.set_xlabel(\"Student\")\n",
    "#     plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BROKEN BECAUSE OF THE ABOVE\n",
    "\n",
    "# for student in students:\n",
    "#     # x is student\n",
    "#     # y is average time\n",
    "#     studentAvgPerRunDf = averagePerRunDf[(averagePerRunDf.SubjectID == student)].copy()\n",
    "#     if studentAvgPerRunDf[ASSIGNMENT_ID_KEY].unique().size > 3:\n",
    "#         ax = sns.barplot(x=ASSIGNMENT_ID_KEY, y='AverageTimePerRun', data=studentAvgPerRunDf)\n",
    "#         ax.set(title=f'Avg Time Between Runs Per Assignment {student}')\n",
    "#         ax.set_ylabel(\"Avg Time Between Runs\")\n",
    "#         ax.set_xlabel(\"Assignment\")\n",
    "#         plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(data=mid_scores_with_behavior_info, y=NUMBER_RUNS_KEY, x=MID_SCORE_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=mid_scores_with_behavior_info, y=INCREMENTAL_KEY, x=SESSION_COUNT_KEY, orient='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=mid_scores_with_behavior_info, y=INCREMENTAL_KEY, x=AVG_EVENTDIFF_TIME_KEY, orient='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=mid_scores_with_behavior_info, y=INCREMENTAL_KEY, x=NUMBER_EVENTS_KEY, orient='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(data=mid_scores_with_behavior_info, y=SESSION_COUNT_KEY, x=MID_SCORE_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(data=mid_scores_with_behavior_info, y=TOTAL_ASSIGNMENT_TIME_KEY, x=MID_SCORE_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(data=mid_scores_with_behavior_info, y=NUMBER_EVENTS_KEY, x=MID_SCORE_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(data=mid_scores_with_behavior_info, y=AVG_EVENTDIFF_TIME_KEY, x=MID_SCORE_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERCENT_BEFORE_SESSION_RUN = 'PercentOfEventsBeforeASessionRun'\n",
    "mid_scores_with_behavior_info[PERCENT_BEFORE_SESSION_RUN] =  mid_scores_with_behavior_info[NUMBER_EVENTS_BEFORE_RUN_IN_SESSION_KEY] / mid_scores_with_behavior_info[NUMBER_EVENTS_KEY]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printMannWhitneyU(series1, series2):\n",
    "    series1 = series1.dropna()\n",
    "    series2 = series2.dropna()\n",
    "    n1 = len(series1)\n",
    "    n2 = len(series2)\n",
    "\n",
    "    support, pVal = mannwhitneyu(series1, series2)\n",
    "\n",
    "    print(f\"(Mann-Whitney U={support:.0f}, {n1=}, {n2=}, p={pVal})\")\n",
    "\n",
    "\n",
    "def printMeanMedianStd(incrementalSeries, nonIncrementalSeries):\n",
    "\n",
    "    print(f\"\"\"\\\n",
    "Incremental N = {len(incrementalSeries.dropna())}\n",
    "Non Incremental N = {len(nonIncrementalSeries.dropna())}\n",
    "\"\"\")\n",
    "\n",
    "    print(f\"\"\"\\\n",
    "Incremental median:\n",
    "{incrementalSeries.median(numeric_only=True)}\n",
    "\"\"\")\n",
    "\n",
    "    print(f\"\"\"\\\n",
    "Non Incremental median:\n",
    "{nonIncrementalSeries.median(numeric_only=True)}\n",
    "\"\"\")\n",
    "\n",
    "    print(f\"\"\"\\\n",
    "Incremental mean:\n",
    "{incrementalSeries.mean(numeric_only=True)}\n",
    "\"\"\")\n",
    "\n",
    "    print(f\"\"\"\\\n",
    "Non Incremental mean:\n",
    "{nonIncrementalSeries.mean(numeric_only=True)}\n",
    "\"\"\")\n",
    "\n",
    "    print(f\"\"\"\\\n",
    "Incremental std:\n",
    "{incrementalSeries.std(numeric_only=True)}\n",
    "\"\"\")\n",
    "\n",
    "    print(f\"\"\"\\\n",
    "Non Incremental std:\n",
    "{nonIncrementalSeries.std(numeric_only=True)}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incremental = mid_scores_with_behavior_info[mid_scores_with_behavior_info.Incremental == 1]\n",
    "nonIncremental = mid_scores_with_behavior_info[mid_scores_with_behavior_info.Incremental == 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Difference In Assignment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printMeanMedianStd(incremental[FINAL_SCORE_KEY], nonIncremental[FINAL_SCORE_KEY])\n",
    "printMannWhitneyU(incremental[FINAL_SCORE_KEY], nonIncremental[FINAL_SCORE_KEY])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference In Number Of Events/Keystrokes/Assignment Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printMeanMedianStd(incremental[NUMBER_EVENTS_KEY], nonIncremental[NUMBER_EVENTS_KEY])\n",
    "printMannWhitneyU(incremental[NUMBER_EVENTS_KEY], nonIncremental[NUMBER_EVENTS_KEY])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference In Time Between Interactions (In Sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printMeanMedianStd(incremental[AVG_EVENTDIFF_TIME_KEY], nonIncremental[AVG_EVENTDIFF_TIME_KEY])\n",
    "printMannWhitneyU(incremental[AVG_EVENTDIFF_TIME_KEY], nonIncremental[AVG_EVENTDIFF_TIME_KEY])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference In Assignment Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printMeanMedianStd(incremental[TOTAL_ASSIGNMENT_TIME_KEY], nonIncremental[TOTAL_ASSIGNMENT_TIME_KEY])\n",
    "printMannWhitneyU(incremental[TOTAL_ASSIGNMENT_TIME_KEY], nonIncremental[TOTAL_ASSIGNMENT_TIME_KEY])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference In Number Of Coding Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printMeanMedianStd(incremental[SESSION_COUNT_KEY], nonIncremental[SESSION_COUNT_KEY])\n",
    "printMannWhitneyU(incremental[SESSION_COUNT_KEY], nonIncremental[SESSION_COUNT_KEY])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference In Assignment Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printMeanMedianStd(incremental[TOTAL_ASSIGNMENT_TIME_KEY], nonIncremental[TOTAL_ASSIGNMENT_TIME_KEY])\n",
    "printMannWhitneyU(incremental[TOTAL_ASSIGNMENT_TIME_KEY], nonIncremental[TOTAL_ASSIGNMENT_TIME_KEY])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference In Number Of Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printMeanMedianStd(incremental[NUMBER_RUNS_KEY], nonIncremental[NUMBER_RUNS_KEY])\n",
    "printMannWhitneyU(incremental[NUMBER_RUNS_KEY], nonIncremental[NUMBER_RUNS_KEY])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference In Time Between Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printMeanMedianStd(incremental[AVG_TIME_BETWEEN_RUNS_KEY], nonIncremental[AVG_TIME_BETWEEN_RUNS_KEY])\n",
    "printMannWhitneyU(incremental[AVG_TIME_BETWEEN_RUNS_KEY], nonIncremental[AVG_TIME_BETWEEN_RUNS_KEY])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference In Percentage Of Events Before A Run In A Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printMeanMedianStd(incremental[PERCENT_BEFORE_SESSION_RUN], nonIncremental[PERCENT_BEFORE_SESSION_RUN])\n",
    "printMannWhitneyU(incremental[PERCENT_BEFORE_SESSION_RUN], nonIncremental[PERCENT_BEFORE_SESSION_RUN])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "5e7cd3a884995e5ac0fa852e707a391ad35b963e757ae698c795d1558dfb018c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
